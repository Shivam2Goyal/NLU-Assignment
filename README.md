# Sports vs Politics Text Classification

This project presents a **binary text classification system** designed to distinguish between **Sports** and **Politics** news articles using classical machine learning techniques and different feature representations.

The work was completed as part of an academic assignment in **Natural Language Processing**.

---

## ðŸ“Œ Project Overview

The objective of this study is to:
- Build a reliable **binary news classifier**.
- Compare multiple **machine learning models**.
- Evaluate different **text feature representations**.
- Perform **error analysis** and identify **system limitations**.

The final system achieves **~98% accuracy** using **Linear SVM with TF-IDF features**.

---

## ðŸ—‚ Dataset

- **Source:** AG News Dataset
- **Original categories:** *World, Sports, Business, Sci/Tech*
- **Classes used in this project:**
  - **World â†’ Politics**
  - **Sports â†’ Sports**

### Dataset Size (after balancing & reduction)

| Split | Samples per Class | Total |
|-------|-------------------|-------|
| Train | 10,000            | 20,000|
| Test  | 1,000             | 2,000 |

The dataset is kept **perfectly balanced** to ensure unbiased learning and evaluation.

---

## âš™ï¸ Preprocessing Steps

The following preprocessing pipeline was applied:
1. **Lowercasing** all text.
2. **Cleaning:** Removing punctuation and non-alphabetic symbols.
3. **Stop-word removal:** Filtering out common filler words.
4. **Vectorization:** TF-IDF conversion for numerical representation.

---

## ðŸ§  Machine Learning Models

Three classical supervised learning algorithms were evaluated:
- **Multinomial Naive Bayes:** Probabilistic approach.
- **Linear Support Vector Machine (SVM):** Margin-based approach.
- **Random Forest:** Ensemble tree-based approach.

---

## ðŸ“Š Quantitative Results

### Overall Model Performance

| Model | Accuracy | F1-Score |
|-------|----------|----------|
| **Linear SVM** | **0.9800** | **0.9800** |
| Naive Bayes | 0.9750 | 0.9750 |
| Random Forest | 0.9580 | 0.9580 |

ðŸ“ˆ **Visualization**
![Model Performance](Results/model_performance_bar.png)

---

### Feature Representation Comparison (Linear SVM)

| Representation | Accuracy | F1-Score |
|----------------|----------|----------|
| **TF-IDF (Unigram)** | **0.9795** | **0.9795** |
| TF-IDF (Uni+Bi-gram) | 0.9790 | 0.9790 |
| Bag of Words (Unigram) | 0.9645 | 0.9645 |

ðŸ“ˆ **Visualization**
![Feature Performance](Results/feature_performance_bar.png)

---

## ðŸ”Ž Confusion Matrix Analysis

### Model Comparison (TF-IDF Bigram)

| Naive Bayes | Linear SVM | Random Forest |
|:---:|:---:|:---:|
| ![Naive Bayes CM](Results/cm_model_naive_bayes.png) | ![Linear SVM CM](Results/cm_model_linear_svm.png) | ![Random Forest CM](Results/cm_model_random_forest.png) |

These matrices show that **Linear SVM produces the fewest misclassifications**, confirming its superior performance.

---

## ðŸ§© Feature Importance Insights

Top indicative words learned by the model:
- **Sports:** `team`, `coach`, `cup`, `league`, `season`, `players`, `olympic`, `game`
- **Politics:** `election`, `minister`, `government`, `president`, `nuclear`, `security`

This demonstrates that the classifier primarily relies on **topic-specific vocabulary**.

---

## âš ï¸ Limitations

Despite strong accuracy, the system has important constraints:
- **Semantic ambiguity:** Words may appear in both domains (e.g., â€œminister of sportsâ€).
- **Temporal bias:** Political vocabulary reflects a specific historical period (e.g., mentions of specific politicians).
- **Keyword dependence:** Lacks deep contextual understanding or word order awareness.
- **No semantic embeddings:** Classical TF-IDF ignores relationships between synonymous words.

---

## ðŸ Conclusion

This project shows that **classical machine learning** combined with **TF-IDF** can achieve **near-98% accuracy** for structured news classification.

> **Linear SVM with TF-IDF** provides the best balance of accuracy, robustness, and computational efficiency.

---

## ðŸ“‚ Repository Structure
```text
â”œâ”€â”€ Results/
â”‚   â”œâ”€â”€ model_performance_bar.png
â”‚   â”œâ”€â”€ feature_performance_bar.png
â”‚   â””â”€â”€ cm_model_*.png
â”œâ”€â”€ data/
|   â”œâ”€â”€ train_processed.csv
|   â”œâ”€â”€ test_processed.csv
â”œâ”€â”€ B23CM1036_prob4.py
â”œâ”€â”€ B23CM1036_prob4.pdf
â””â”€â”€ README.md
